# Multimodel_agent
A powerful ChatGPT-like AI agent that supports both text and image inputs using Google's Gemini API. Built without transformers for easy deployment and fast responses.
# ğŸ¤– Multi-Modal AI Agent using Google Gemini API

This project is a ChatGPT-like multi-modal AI agent powered by **Google Gemini**. It allows users to:
- ğŸ’¬ Ask text-based questions and receive intelligent responses
- ğŸ–¼ï¸ Upload images along with a prompt to get context-aware, vision-language-based answers

Built with **Streamlit** for the web interface and supports an alternative **command-line version**.

---

## ğŸš€ Features

- âœ… Gemini 1.5 Flash model support
- âœ… Text-only and image+text multimodal inputs
- âœ… Streamlit-based user interface
- âœ… CLI version for quick terminal usage
- âœ… Lightweight and easy to run locally

---

## ğŸ–¼ï¸ Demo

![demo]()  
*Example: Upload an image of a car and ask â€œWhat kind of car is this?â€*

---
## Output
<img width="1920" height="1080" alt="image" src="https://github.com/user-attachments/assets/1b760ad6-9ad3-4741-b028-ef3a2896516d" />

## ğŸ”§ Requirements

- Python 3.8+
- `streamlit`
- `pillow`
- `google-generativeai`

---

## ğŸ“¦ Installation

1. **Clone the repo**
```bash
git clone https://github.com/yourusername/multimodal-ai-agent.git
cd multimodal-ai-agent
