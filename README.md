# Multimodel_agent
A powerful ChatGPT-like AI agent that supports both text and image inputs using Google's Gemini API. Built without transformers for easy deployment and fast responses.
# 🤖 Multi-Modal AI Agent using Google Gemini API

This project is a ChatGPT-like multi-modal AI agent powered by **Google Gemini**. It allows users to:
- 💬 Ask text-based questions and receive intelligent responses
- 🖼️ Upload images along with a prompt to get context-aware, vision-language-based answers

Built with **Streamlit** for the web interface and supports an alternative **command-line version**.

---

## 🚀 Features

- ✅ Gemini 1.5 Flash model support
- ✅ Text-only and image+text multimodal inputs
- ✅ Streamlit-based user interface
- ✅ CLI version for quick terminal usage
- ✅ Lightweight and easy to run locally

---

## 🖼️ Demo

![demo]()  
*Example: Upload an image of a car and ask “What kind of car is this?”*

---
## Output
<img width="1920" height="1080" alt="image" src="https://github.com/user-attachments/assets/1b760ad6-9ad3-4741-b028-ef3a2896516d" />

## 🔧 Requirements

- Python 3.8+
- `streamlit`
- `pillow`
- `google-generativeai`

---

## 📦 Installation

1. **Clone the repo**
```bash
git clone https://github.com/yourusername/multimodal-ai-agent.git
cd multimodal-ai-agent
